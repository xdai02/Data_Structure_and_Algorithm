<center><h1>数据结构</h1></center>

<div style="border-bottom: none;"><center><h3>目录</h3></center></div>

[TOC]

<div style="page-break-after: always;"></div>

# 第3章 链表

## 3.1 链表

**单向链表（Singly Linked List）**

为避免元素的移动，采用线性表的另一种存储方式：链式存储结构。链表是一种在物理上非连续、非顺序的数据结构，由若干结点（node）所组成。

单向链表的每一个结点又包含两部分，一部分是存放数据的数据域`data`，另一部分是指向下一个结点的指针域`next`。结点可以在运行时动态生成。

```c
typedef struct Node {
    dataType data;          // 数据域
    struct Node *next;		// 指针域
} Node;
```

链表的第一个结点被称为头结点，最后一个节点被称为尾结点，尾结点的`next`指针指向空`NULL`。

![](./img/C3/3-1/1.png)

与数组按照下标来随机寻找元素不同，对于链表的其中一个结点A，只能根据结点A的next指针来找到该结点的下一个结点B，再根据结点B的`next`指针找到下一个节点C……

数组在内存中的存储方式是顺序存储，链表在内存中的存储方式则是随机存储。链表采用了见缝插针的方式，每一个结点分布在内存的不同位置，依靠`next`指针关联起来。这样可以灵活有效地利用零散的碎片空间。



**双向链表（Doubly Linked List）**

那么，通过链表的一个结点，如何能快速找到它的前一个结点呢？要想让每个结点都能回溯到它的前置结点，可以使用双向链表。

双向链表比单向链表稍微复杂一点，它的每一个结点除了拥有`data`和`next`指针，还拥有指向前置结点的`prev`指针。

![](./img/C3/3-1/2.png)

| 单向链表特点                                 | 双向链表特点                                   |
| -------------------------------------------- | ---------------------------------------------- |
| 只能从头到尾遍历，只能找到后继，无法找到前驱 | 需要多分配一个指针的存储空间                   |
| 遍历的时候不会死循环                         | 每个结点有两个指针，分别指向直接前驱和直接后继 |
|                                              | 可以找到前驱和后继，可进可退                   |



**循环链表（Circular Linked List）**

除了单向链表和双向链表以外，还有循环链表。

对于单向循环链表，尾结点的`next`指针指向头结点。

对于双向循环链表，尾结点的`next`指针指向头结点，并且头结点的`prev`指针指向尾结点。

![](./img/C3/3-1/3.png)

<div style="page-break-after: always;"></div>

## 3.2 链表的增删改查

**查找结点**

在查找元素时，链表不像数组那样可以通过下标快速进行定位，只能从头结点开始向后一个一个结点逐一查找。

例如在一个链表中查找第3个结点：

<img src="./img/C3/3-2/1.png" style="zoom:80%;" />

链表中的数据只能按顺序进行访问，最坏的时间复杂度是$ O(n) $。

---

【代码】查找结点

```c
Node* search(List *head, dataType val) {
    // 查找元素位置
    Node *temp = head;
    while(temp) {
        if(temp->data == val) {
            return temp;
        }
        temp = temp->next;
    }
    return NULL;        // 未找到
}
```

---



**更新结点**

如果不考虑查找结点的过程，链表的更新过程会像数组那样简单，直接把旧数据替换成新数据即可。

<img src="./img/C3/3-2/2.png" style="zoom: 67%;" />

---

【代码】更新结点

```c
void replace(List *head, int pos, dataType val) {
    // 找到元素位置
	Node *temp = head;
    for(int i = 0; i < pos; i++) {
        temp = temp->next;
    }
    temp->data = val;
}
```

---



**插入结点**

链表插入结点，分为3种情况：

1. 尾部插入：把最后一个结点的`next`指针指向新插入的结点。

<img src="./img/C3/3-2/3.png" style="zoom: 67%;" />

2. 头部插入：先把新结点的`next`指针指向原先的头结点，再把新结点设置为链表的头结点。

<img src="./img/C3/3-2/4.png" style="zoom: 80%;" />

3. 中间插入：先把新结点的`next`指针指向插入位置的结点，再将插入位置的前置结点的`next`指针指向新结点。

<img src="./img/C3/3-2/5.png" style="zoom: 80%;" />

只要内存空间允许，能够插入链表的元素是无穷无尽的，不需要像数组考虑扩容的问题。如果不考虑插入之前的查找元素的过程，只考虑纯粹的插入操作，时间复杂度是$ O(1) $。



**删除结点**

链表的删除操作也分3种情况：

1. 尾部删除：把倒数第二个结点的`next`指针指向空。

<img src="./img/C3/3-2/6.png" style="zoom: 80%;" />

2. 头部删除：把链表的头结点设置为原先头结点的`next`指针。

<img src="./img/C3/3-2/7.png" style="zoom: 80%;" />

3. 中间删除：把要删除的结点的前置结点的`next`指针，指向要删除结点的下一个结点。

<img src="./img/C3/3-2/8.png" style="zoom: 80%;" />

许多高级语言，如`Java`，拥有自动化的垃圾回收机制，所以不用刻意去释放被删除的结点，只要没有外部引用指向它们，被删除的结点会被自动回收。

如果不考虑删除操作之前的查找的过程，只考虑纯粹的删除操作，时间复杂度是$ O(1) $。

<div style="page-break-after: always;"></div>

## 3.3 带头结点的链表

**带头结点的链表**

为了方便链表的插入、删除操作，在链表加上头结点之后，无论链表是否为空，头指针始终指向头结尾。因此对于空表和非空表的处理也统一了，方便了链表的操作，也减少了程序的复杂性和出现bug的机会。

---

【代码】插入结点

```c
void insert(List *head, int pos, dataType val) {
    Node *newNode = (Node *)malloc(sizeof(Node));
    newNode->data = val;
    newNode->next =  NULL;
    
    // 找到插入位置
    Node *temp = head;
    for(int i = 0; i < pos; i++) {
        temp = temp->next;
    }
    newNode->next = temp->next;
    temp->next = newNode;
}
```

---

【代码】删除结点

```c
void delete(List *head, int pos) {
    Node *temp = head;
    for(int i = 0; i < pos; i++) {
        temp = temp->next;
    }
    Node *del = temp->next;
    temp->next = del->next;
    free(del);
    del = NULL;
}
```

---



**数组VS链表**

数据结构没有绝对的好与坏，数组和链表各有千秋。

|    比较内容    |          数组          |             链表             |
| :------------: | :--------------------: | :--------------------------: |
|    **基本**    |  一组固定数量的数据项  |       可变数量的数据项       |
|    **大小**    |      声明期间指定      | 无需指定，执行期间增长或收缩 |
|  **存储分配**  | 元素位置在编译期间分配 |     元素位置在运行时分配     |
|  **元素顺序**  |        连续存储        |           随机存储           |
|  **访问元素**  |  直接访问：索引、下标  |      顺序访问：指针遍历      |
| **插入/删除**  |         速度慢         |          快速、高效          |
|    **查找**    |   二分查找、线性查找   |           线性查找           |
| **内存利用率** |          低效          |             高效             |

数组的优势在于能够快速定位元素，对于读操作多、写操作少的场景来说，用数组更合适一些。

相反，链表的优势在于能够灵活地进行插入和删除操作，如果需要频繁地插入、删除元素，用链表更合适一些。

|          |   查找   |   更新   |   插入   |   删除   |
| :------: | :------: | :------: | :------: | :------: |
| **数组** | $ O(1) $ | $ O(1) $ | $ O(n) $ | $ O(n) $ |
| **链表** | $ O(n) $ | $ O(n) $ | $ O(1) $ | $ O(1) $ |

<div style="page-break-after: always;"></div>

## 3.4 倒数第k个结点

**倒数第k个结点**

输入一个链表，输出该链表中倒数第k个结点。例如一个链表有6个结点[0, 1, 2, 3, 4, 5]，这个链表的倒数第3个结点是值为3的结点。

算法的思路是设置两个指针p1和p2，它们都从头开始出发，p2指针先出发k个结点，然后p1指针再进行出发，当p2指针到达链表的尾结点时，则p1指针的位置就是链表的倒数第k个结点。

---

【代码】倒数第k个结点

```java
public static Node findLastKth(LinkedList list, int k) {
    Node p1 = list.getHead();
    Node p2 = list.getHead();

    int i = 0;
    while(p2 != null && i < k) {
        p2 = p2.next;
        i++;
    }
    while(p2 != null) {
        p1 = p1.next;
        p2 = p2.next;
    }
    return p1;
}
```

---

<div style="page-break-after: always;"></div>

## 3.5 逆序输出链表

**逆序输出链表**

输入一个单链表，从尾到头打印链表每个结点的值。

由于单链表的遍历只能从头到尾，所以可以通过递归达到链表尾部，然后在回溯时输出每个结点的值。根据栈先进后出的特性，可以把链表的结点全部放入栈中，然后依次取出栈顶的位置即可。

---

【代码】逆序输出链表（递归）

```java
public static void inverse(Node head) {
    if(head != null) {
        inverse(head.next);
        System.out.print(head.data + " ");
    }
}
```

---

【代码】逆序输出链表（非递归）

```java
public static void inverseNonRecursive(LinkedList list) {
    Stack s = new Stack();

    Node node = list.getHead();
    while(node != null) {
        s.push(node);
        node = node.next;
    }
    while(!s.isEmpty()) {
        System.out.print(s.pop().data + " ");
    }
    System.out.println();
}
```

---

<div style="page-break-after: always;"></div>

## 3.6 环形链表

**环形链表**

一个单向链表中有可能出现环，不允许修改链表结构，如何在时间复杂度$ O(n) $、空间复杂度$ O(1) $内判断出这个链表是有环链表？如果带环，环的长度是多少？环的入口结点是哪个？

暴力算法首先从头结点开始，依次遍历单链表的每一个结点。对于每个结点都从头重新遍历之前的所有结点。如果发现当前结点与之前结点存在相同ID，则说明该结点被遍历过两次，链表有环。但是这种方法的时间复杂度太高。

另一种方法就是利用快慢指针，首先创建两个指针p1和p2，同时指向头结点，然后让p1每次向后移动一个位置，让p2每次向后移动两个位置。在环中，快指针一定会反复遇到慢指针。比如在一个环形跑道上，两个运动员在同一地点起跑，一个运动员速度快，一个运动员速度慢。当两人跑了一段时间，速度快的运动员必然会从速度慢的运动员身后再次追上并超过。

环的长度可以通过从快慢指针相遇的结点开始再走一圈，下一次回到该点的时的移动步数，即环的长度n。

环的入口可以利用类似获取链表倒数第k个结点的方法，准备两个指针p1和p2，让p2先走n步，然后p1和p2一块走。当两者相遇时，即为环的入口处。

---

【代码】环形链表

```java
public static Node cycleNode(LinkedList list) {
    Node p1 = list.getHead();
    Node p2 = list.getHead();

    while(p1 != null && p2 != null) {
        if(p2.next == null || p2.next.next == null) {
            return null;
        }
        p1 = p1.next;
        p2 = p2.next.next;
        if(p1 == p2) {
            return p1;
        }
    }
    return null;
}

public static int cycleLength(LinkedList list) {
    Node node = cycleNode(list);
    if(node == null) {
        return 0;
    }
    int len = 1;
    Node cur = node.next;
    while(cur != node) {
        cur = cur.next;
        len++;
    }
    return len;
}

public static Node cycleEntrance(LinkedList list) {
    int n = cycleLength(list);
    if(n == 0) {
        return null;
    }

    Node p1 = list.getHead();
    Node p2 = list.getHead();
    for(int i = 0; i < n; i++) {
        p2 = p2.next;
    }

    while(p1 != p2) {
        p1 = p1.next;
        p2 = p2.next;
    }
    return p1;
}
```

---

<div style="page-break-after: always;"></div>

## 3.7 反转链表

**反转链表**

反转一个链表需要调整链表中指针的方向。

递归反转法的实现思想是从链表的尾结点开始，依次向前遍历，遍历过程依次改变各结点的指向，即另其指向前一个结点。

而迭代反转法的实现思想非常直接，就是从当前链表的首结点开始，一直遍历至链表尾部，期间会逐个改变所遍历到的结点的指针域，另其指向前一个结点。

```mermaid
graph LR
	node1[A] --> node2[B] --> node3[C] --> node4[D] --> node5[E] --> node6[F]
	node7[F] --> node8[E] --> node9[D] --> node10[C] --> node11[B] --> node12[A]
```

---

【代码】反转链表（递归）

```java
public static Node reverseList(Node head) {
    if(head == null || head.next == null) {
        return head;
    }
    Node next = head.next;
    head.next = null;
    Node newHead = reverseList(next);
    next.next = head;
    return newHead;
}
```

---

【代码】反转链表（迭代）

```java
public static Node reverseListIterative(LinkedList list) {
    Node newHead = new Node(-1);
    Node head = list.getHead();
    while(head != null) {
        Node next = head.next;
        head.next = newHead.next;
        newHead.next = head;
        head = next;
    }
    return newHead.next;
}
```

---

<div style="page-break-after: always;"></div>

## 3.8 跳表

**跳表（Skip List）**

给定一个有序链表，如何根据给定元素的值进行高效率查找？

![](./img/C3/3-8/1.png)

<img src="./img/C3/3-8/2.png" style="zoom:80%;" />

<img src="./img/C3/3-8/3.png" style="zoom:80%;" />

<img src="./img/C3/3-8/4.png" style="zoom:80%;" />

<img src="./img/C3/3-8/5.png" style="zoom:80%;" />

<img src="./img/C3/3-8/6.png" style="zoom:80%;" />

<img src="./img/C3/3-8/7.png" style="zoom:80%;" />

![](./img/C3/3-8/8.png)

在原始链表的基础上，增加了一个索引链表。原始链表的每两个结点，有一个结点在索引链表当中。当需要查找结点20的时候，不需要在原始链表中一个一个结点访问，而是首先访问索引链表。

![](./img/C3/3-8/9.png)

在索引链表找到结点20之后，顺着索引链表的结点向下，找到原始链表的结点20。

![](./img/C3/3-8/10.png)

这个过程，就像是先查阅了图书的目录，再翻到章节所对应的页码。由于索引链表的结点个数是原始链表的一半，查找结点所需的访问次数也相应减少了一半。

<img src="./img/C3/3-8/11.png" style="zoom:80%;" />

<img src="./img/C3/3-8/12.png" style="zoom:80%;" />

![](./img/C3/3-8/13.png)

基于原始链表的第1层索引，抽出了第2层更为稀疏的索引，结点数量是第1层索引的一半。这样的多层索引可以进一步提升查询效率。

![](./img/C3/3-8/14.png)

![](./img/C3/3-8/15.png)

![](./img/C3/3-8/16.png)

假设原始链表有$ n $个结点，那么索引的层级就是$ logn - 1 $，在每一层的访问次数是常量，因此查找结点的平均时间复杂度是$ O(logn) $，这比起常规的线性查找效率要高得多。

但相应的，这种基于链表的优化增加了额外的空间开销，各层索引的结点总数是$ {n \over 2} + {n \over 4} + {n \over 8} + {n \over 16} + \dots \approx n $。也就是说，优化之后的数据结构所占空间，是原来的2倍，这是典型的以空间换时间的做法。

<img src="./img/C3/3-8/17.png" style="zoom:80%;" />

<img src="./img/C3/3-8/18.png" style="zoom:80%;" />

假设要插入的结点是10，首先按照跳表查找结点的方法，找到待插入结点的前置结点（仅小于待插入结点）。

![](./img/C3/3-8/19.png)

按照一般链表的插入方式，把结点10插入到结点9的下一个位置。

![](./img/C3/3-8/20.png)

这样是不是插入工作就完成了呢？并不是。随着原始链表的新结点越来越多，索引会渐渐变得不够用了，因此索引结点也需要相应作出调整。

调整索引的方法就是让新插入的结点随机晋升成为索引结点，晋升成功的几率是50%。

![](./img/C3/3-8/21.png)

新结点在成功晋升之后，仍然有机会继续向上一层索引晋升。

<img src="./img/C3/3-8/22.png" style="zoom:80%;" />

假设要从跳表中删除结点10，首先按照跳表查找结点的方法，找到待删除的结点。按照一般链表的删除方式，把结点10从原始链表当中删除。

这样是不是删除工作就完成了呢？并不是。还需要顺藤摸瓜，把索引当中的对应结点也一一删除。

![](./img/C3/3-8/23.png)

<img src="./img/C3/3-8/24.png" style="zoom:80%;" />

<img src="./img/C3/3-8/25.png" style="zoom:80%;" />

<img src="./img/C3/3-8/26.png" style="zoom:80%;" />

1. 程序中跳表采用的是双向链表，无论前后结点还是上下结点，都各有两个指针相互指向彼此。
2. 程序中跳表的每一层首尾各有一个空结点，左侧的空节点是负无穷大，右侧的空节点是正无穷大。

![](./img/C3/3-8/27.png)

<img src="./img/C3/3-8/28.png" style="zoom:80%;" />

<div style="page-break-after: always;"></div>

# 第4章 栈

## 4.1 栈

**栈（Stack）**

栈，又名堆栈，是一种运算受限的线性数据结构，栈只能在表尾进行插入和删除操作。

栈中的元素只能先进后出（`FILO`, First In Last Out）。最早进入栈的元素所存放的位置叫作栈底（bottom），最后进入栈的元素存放的位置叫作栈顶（top）。

<img src="./img/C4/4-1/1.png" style="zoom:80%;" />

<img src="./img/C4/4-1/2.png" style="zoom: 70%;" />

向一个栈插入新元素的操作称为入栈`push`（或进栈、压栈），从一个栈删除元素的操作称为出栈`pop`（或退栈、弹栈）。

![](./img/C4/4-1/3.png)

栈这种数据结构既可以用数组来实现，也可以用链表来实现。



**顺序栈**

使用数组方式实现的栈称为静态栈。可以根据下标来表示栈顶在数组中的位置，对于空栈，栈顶为`-1`。

进行入栈操作时，栈顶指针`+1`；出栈时，栈顶指针`-1`。

![](./img/C4/4-1/4.png)

对满栈进行入栈和对空栈进行出栈操作操作都会产生数组的越界并引起程序崩溃，称为`上溢`和`下溢`。因此使用顺序栈前需要提前声明一个数组的大小，如果数组大小不够则可能发生数组越界，如果数组太大则会浪费一定的空间。

使用数组实现的栈的执行效率会比用链表来实现的高，入栈和出栈不需要移动大量元素，只需要移动栈顶指针即可。



**链式栈**

使用链表方式实现的栈称为动态栈。通过在表头插入一个元素来实现入栈，通过删除表尾元素来实现出栈。

动态栈有链表的部分特性，元素与元素之间在物理存储上可以不连续，但是功能有些受限制，动态栈只能在栈顶处进行插入和删除操作，不能在栈尾或栈中间进行插入和删除操作。

![](./img/C4/4-1/5.png)

动态栈的元素内存是动态分配的，避免了静态栈可能会浪费空间的问题，但是对申请`malloc`和释放`free`空间的调用开销会比较大。



**入栈（Push）**

入栈操作就是把新元素放入栈中，只允许从栈顶一侧放入元素，新元素的位置将会成为新的栈顶。

最初，栈为空，栈顶的初始值为`-1`。每当向栈中添加元素时，栈顶指针`+1`。

<img src="./img/C4/4-1/6.png" style="zoom:80%;" />

---

【代码】入栈

```c
void push(Stack *stack, dataType val) {
    stack->data[++stack->top] = val;
}
```

---

入栈只影响最后一个元素，不涉及元素的整体移动，所以无论是以数组还是链表实现，时间复杂度都是$ O(1) $。



**出栈（Pop）**

出栈操作就是把新元素从栈中弹出，只有栈顶元素才允许出栈，出栈元素的前一个元素将会成为新的栈顶。

从栈中移出元素，栈顶指针`-1`。数组中元素的删除并非真正意义上把元素从内存中清除，出栈只需对栈顶`-1`即可，后期向栈中添加元素时，新元素会将旧元素覆盖。

<img src="./img/C4/4-1/7.png" style="zoom:80%;" />

---

【代码】出栈

```c
dataType pop(Stack *stack) {
    return stack->data[stack->top--];
}
```

---

出栈只影响最后一个元素，不涉及元素的整体移动，所以无论是以数组还是链表实现，时间复杂度都是$ O(1) $。



**栈的应用**

栈的输出顺序和输入顺序相反，所以栈同行用于对历史的回溯。例如实现递归的逻辑，就可以用栈回溯调用链。

<img src="./img/C4/4-1/8.png" style="zoom:67%;" />

栈还有一个著名的应用场景就是面包屑导航，使用户在流浪页面时可以轻松地回溯到上一级更更上一级页面。

![](./img/C4/4-1/9.png)

<div style="page-break-after: always;"></div>

## 4.2 最小栈

**最小栈**

设计一个支持`push()`、`pop()`、`peek()`和`getMin()`操作的栈，并能在常数时间内检索到最小元素。

对于栈来说，如果一个元素a在入栈时，栈里有其它的元素b、c、d，那么无论这个栈在之后经历了什么操作，只要a在栈中，b、c、d就一定在栈中。因此，在操作过程中的任意一个时刻，只要栈顶的元素是a，那么就可以确定栈里面现在的元素一定是a、b、c、d。

那么可以在每个元素a入栈时把当前栈的最小值m存储起来。在这之后无论何时，如果栈顶元素是a，就可以直接返回存储的最小值m。

当一个元素要入栈时，取辅助栈的栈顶存储的最小值，与当前元素比较得出最小值，将这个最小值插入辅助栈中。当一个元素要出栈时，把辅助栈的栈顶元素也一并弹出。这样在任意一个时刻，栈内元素的最小值就存储在辅助栈的栈顶元素中。

---

【代码】最小栈

```python
class MinStack:
    def __init__(self):
        self.stack = []
        self.min_stack = [math.inf]
    
    def push(self, data):
        self.stack.append(data)
        self.min_stack.append(min(data, self.min_stack[-1]))
    
    def pop(self):
        self.stack.pop()
        self.min_stack.pop()
    
    def peek(self):
        return self.stack[-1]
    
    def get_min(self):
        return self.min_stack[-1]
```

---

<div style="page-break-after: always;"></div>

## 4.3 括号匹配

**括号匹配**

给定一个只包括`(`、`)`、`[`、`]`、`{`和`}`的字符串，判断字符串是否有效。有效字符串需满足左括号必须用相同类型的右括号闭合，并且左括号必须以正确的顺序闭合。

判断括号的有效性可以使用栈来解决。通过遍历字符串，当遇到左括号时，会期望在后续的遍历中，有一个相同类型的右括号将其闭合。由于后遇到的左括号要先闭合，因此将这个左括号放入栈顶。

当遇到右括号时，需要将一个相同类型的左括号闭合。此时可以取出栈顶的左括号并判断它们是否是相同类型的括号。如果不是相同的类型，或者栈中并没有左括号，那么字符串无效。为了快速判断括号的类型，可以使用哈希表存储每一种括号，哈希表的键为右括号，值为相同类型的左括号。

在遍历结束后，如果为空栈，说明字符串中的所有左括号闭合。

注意有效字符串的长度一定为偶数，因此如果字符串的长度为奇数，可以直接返回判断出字符串无效，省去后续的遍历判断过程。

---

【代码】括号匹配

```python
def valid_paratheses(s):
    if len(s) % 2 == 1:
        return False
    
    pairs = {")": "(", "]": "[", "}": "{"}
    stack = list()
    for paran in s:
        if paran in pairs:
            if not stack or stack[-1] != pairs[paran]:
                return False
            stack.pop()
        else:
            stack.append(paran)

    return not stack
```

---

<div style="page-break-after: always;"></div>

## 4.4 表达式求值

**表达式求值**

逆波兰表达式是一种后缀表达式，所谓后缀就是指运算符写在运算数的后面。平常使用的算式则是一种中缀表达式，如$ (1 + 2) * (3 + 4) $，该算式的逆波兰表达式写法为$ 1\ 2 + 3\ 4 + * $。

逆波兰表达式的优点在于去掉了中缀表达式中的括号后表达式无歧义，因此

适合用栈操作运算。遇到数字则入栈，遇到算符则取出栈顶两个数字进行计算，并将结果压入栈中。

在对中缀表达式求值时，一般都会将其转换为后缀表达式的形式，转换过程同样需要用到栈，规则如下：

1. 如果遇到操作数，就直接将其输出。
2. 如果遇到左括号，将其放入栈中。
3. 如果遇到右括号，则一直出栈并输出，直到遇到左括号为止。注意，左括号只出栈并不输出。
4. 如果遇到任何其它的运算符，如果为栈为空，则直接入栈。否则从栈中出栈元素并输出，直到遇到优先级更低的元素（或者栈为空）位置。在出栈完这些元素后，再将当前遇到的运算符入栈。有一点需要注意，只有在遇到右括号的情况下才将左括号出栈，其它情况都不会出栈左括号。
5. 如果读取到了表达式的末尾，则将栈中所有元素依次出栈输出。

![](./img/C4/4-4/1.png)

![](./img/C4/4-4/2.png)

![](./img/C4/4-4/3.png)

![](./img/C4/4-4/4.png)

![](./img/C4/4-4/5.png)

![](./img/C4/4-4/6.png)

![](./img/C4/4-4/7.png)

![](./img/C4/4-4/8.png)

![](./img/C4/4-4/9.png)

![](./img/C4/4-4/10.png)

---

【代码】表达式求值

```python
def priority(op):
    """
        运算符的优先级
        乘除法优先级高于加减法
        Args:
            op (str): 运算符
        Returns:
            (int): 优先级
    """
    if op == "*" or op == "/":
        return 2
    elif op == "+" or op == "-":
        return 1
    else:
        return 0

def infix_to_postfix(exp):
    """
        中缀表达式转换后缀表达式
        转换后的后缀表达式操作数之前带空格
        Args:
            exp (str): 中缀表达式
        Returns:
            (str): 后缀表达式
    """
    postfix = ""    # 保存生成的后缀表达式
    s = stack.Stack()

    number = ""
    for ch in exp:
        # 如果是数字，保存每一位数字
        if ch.isdigit():
            number += ch
            continue
        
        # 如果读取一个完整数字，直接输出
        if len(number) > 0:
            postfix += number + " "
            number = ""
        
        # 空格忽略
        if ch == " ":
            continue
        
        # 如果是运算符，并且空栈，则直接入栈
        if s.is_empty():
            s.push(ch)
        # 如果遇到左括号，将其放入栈中
        elif ch == "(":
            s.push(ch)
        # 如果遇到右括号，则一直出栈并输出，直到遇到左括号为止
        # 注意，左括号只出栈并不输出
        elif ch == ")":
            while s.peek() != "(":
                postfix += s.pop() + " "
            s.pop()
        # 如果遇到任何其它的运算符，如果为栈为空，则直接入栈
        # 否则从栈中出栈元素并输出，直到遇到优先级更低的元素（或为空）
        # 在出栈完这些元素后，再将当前遇到的运算符入栈
        # 只有遇到右括号的情况下才将左括号出栈
        else:
            while not s.is_empty() 
            	  and priority(ch) <= priority(s.peek()):
                postfix += s.pop() + " "
            s.push(ch)
    
    # 如果读取一个完整数字，直接输出
    if len(number) > 0:
        postfix += number + " "
        number = ""
    
    while not s.is_empty():
        postfix += s.pop() + " "
    
    return postfix.rstrip()

def calculate(postfix):
    """
    表达式求值
    Args:
        postfix (str): 后缀表达式
    Returns:
        (int): 表达式结果
    """
    s = stack.Stack()

    tokens = postfix.split()
    for token in tokens:
        # 数字则入栈
        try:
            s.push(int(token))
        # 运算符则出栈2次，将计算结果入栈
        except ValueError:
            num2 = s.pop()
            num1 = s.pop()
            if token == '+':
                s.push(num1 + num2)
            elif token == '-':
                s.push(num1 - num2)
            elif token == '*':
                s.push(num1 * num2)
            elif token == '/':
                s.push(int(num1 / num2))
    return s.pop()
```

---

<div style="page-break-after: always;"></div>

# 第5章 队列

## 5.1 队列

**队列（Queue）**

队列是一种运算受限的线性数据结构，不同于栈的先进后出（`FILO`），队列中的元素只能先进先出（`FIFO`, First In First Out）。

队列的出口端叫作队头（`front`），队列的入口端叫作队尾（`rear`）。队列只允许在队尾进行入队（`enqueue`），在队头进行出队（`dequeue`）。

与栈类似，队列既可以用数组来实现，也可以用链表来实现。其中用数组实现时，为了入队操作的方便，把队尾位置规定为最后入队元素的下一个位置。

![](./img/C5/5-1/1.png)

![](./img/C5/5-1/2.png)



**入列（enqueue）**

入队就是把新元素放入队列中，只允许在队尾的位置放入元素，新元素的下一个位置将会成为新的队尾。

![](./img/C5/5-1/3.png)

入队操作的时间复杂度是$ O(1) $。



**出队（dequeue）**

出队就是把元素移出队列，只允许在队头一侧移出元素，出队元素的后一个元素将成为新的队头。

![](./img/C5/5-1/4.png)

出队操作的时间复杂度是$ O(1) $。

<div style="page-break-after: always;"></div>

## 5.2 循环队列

**循环队列（Circular Queue）**

![](./img/C5/5-2/1.png)

用数组实现的队列可以采用循环队列的方式来维持队列容量的恒定。为充分利用空间，克服假溢出的现象，在数组不做扩容的情况下，将队列想象为一个首尾相接的圆环，可以利用已出队元素留下的空间，让队尾指针重新指回数组的首位。这样一来整个队列的元素就循环起来了。

<img src="./img/C5/5-2/2.png" style="zoom:50%;" />

在物理存储上，队尾的位置也可以在队头之前。当再有元素入队时，将其放入数组的首位，队尾指针继续后移即可。队头和队尾互相追赶，这个追赶的过程就是入队的出队的过程。

如果队尾追上队头说明队列满了，如果队头追上队尾说明队列为空。循环队列并非真正地把数组弯曲，利用求余操作就能使队头和队尾指针不会跑出数组的范围，逻辑上实现了弯曲的效果。

假设数组长度为`MAX`：

- 入队时队尾指针后移：$ (rear + 1)\ \%\ MAX $
- 出队时队头指针后移：$ (front + 1)\ \%\ MAX $
- 判断队满：$ (rear + 1)\ \%\ MAX == front $
- 判断队空：$ front == rear $

需要注意的是，队尾指针指向的位置永远空出一位，所以队列最大容量比数组长度小`1`。

---

【代码】入队

```c
void enqueue(Queue *queue, dataType val) {
    queue->data[queue->rear] = val;
    queue->rear = (queue->rear + 1) % queue->max;
}
```

---

【代码】出队

```c
dataType dequeue(Queue *queue) {
    dataType ret = queue->data[queue->front];
    queue->front = (queue->front + 1) % queue->max;
    return ret;
}
```

---

<div style="page-break-after: always;"></div>

## 5.3 栈实现队列

**栈实现队列**

栈是特性是`FILO`，而队列是`FIFO`，因此可以使用两个栈来实现队列的效果。

可以将一个栈当作输入栈，用于`push`数据，另一个栈当作输出栈，用于`pop`和`peek`数据。每次`pop`或`peek`时，若输出栈为空则将输入栈的全部数据依次弹出并压入输出栈，这样输出栈从栈顶往栈底的顺序就是队列从队首往队尾的顺序。

用两个栈来实现队列的情况在生活中也经常出现。去医院挂号等待，等待的时候把病历给护士, 护士面前放了两堆病历。等着无聊就看护士是怎么管理病历的。发现一个堆是倒着放的，一个堆是正着放的。新过来的病人把病历给她时，她就把病历倒着放到第一堆，有病人看病结束后，从第二堆的开头翻一个新的病历，然后叫病人。如果第二堆没了话，就直接把第一堆翻过来放到第二推上面。

![](./img/C5/5-3/1.png)

---

【代码】栈实现队列

```python
class Queue:
    def __init__(self):
        self.in_stack = list()
        self.out_stack = list()
    
    def is_empty(self):
        return not self.in_stack and not self.out_stack

    def enqueue(self, data):
        self.in_stack.append(data)
    
    def dequeue(self):
        if not self.out_stack:
            while self.in_stack:
                self.out_stack.append(self.in_stack.pop())
        return self.out_stack.pop()
```

---

用双栈实现的队列`push`的时间复杂度为$ O(1) $，`pop`和`peek`为均摊$ O(1) $，因为对于每个元素，至多入栈和出栈各两次。

<div style="page-break-after: always;"></div>

## 5.4 队列实现栈

**两个队列实现栈**

为了满足栈的特性，在使用队列实现栈时，应满足队列前端的元素是最后入栈的元素。可以使用两个队列实现栈的操作，其中queue1用于存储栈内的元素，queue2作为入栈操作的辅助队列。

入栈操作时，首先将元素入队到queue2，然后将queue1的全部元素依次出队并入队到queue2，此时queue2的前端的元素即为新入栈的元素，再将queue1和queue2互换，则queue1的元素即为栈内的元素，queue1的前端和后端分别对应栈顶和栈底。

由于queue1用于存储栈内的元素，判断栈是否为空时，只需要判断queue1是否为空即可。

![](./img/C5/5-4/1.png)



**一个队列实现栈**

在两个队列实现栈的方法中，其中一个队列的作用相当于临时变量。因此只使用一个队列就能实现栈了。

入栈操作时，首先获得入栈前的元素个数$ n $，然后将元素入队到队列，再将队列中的前$ n $个元素（即除了新入栈的元素之外的全部元素）依次出队并入队到队列，此时队列的前端的元素即为新入栈的元素，且队列的前端和后端分别对应栈顶和栈底。

![](./img/C5/5-4/2.png)

---

【代码】队列实现栈

```python
import collections

class Stack:
    def __init__(self):
        self.queue = collections.deque()
    
    def is_empty(self):
        return not self.queue

    def push(self, data):
        n = len(self.queue)
        self.queue.append(data)
        for _ in range(n):
            self.queue.append(self.queue.popleft())
    
    def pop(self):
        return self.queue.popleft()
    
    def peek(self):
        return self.queue[0]
```

---

<div style="page-break-after: always;"></div>

## 5.5 双端队列

**双端队列（Deque, Double Ended Queue）**

双端队列是一种同时具有队列和栈的性质的数据结构，双端队列可以从其两端插入和删除元素。

---

【代码】双端队列

```python
class Deque:
    def __init__(self):
        self.data = []

    def is_empty(self):
        return not self.data

    def add_front(self, val):
        self.data.insert(0, val)

    def add_rear(self, val):
        self.data.append(val)

    def remove_front(self):
        if not self.is_empty():
            return self.data.pop(0)

    def remove_rear(self):
        if not self.is_empty():
            return self.data.pop()

    def get_front(self):
        if not self.is_empty():
            return self.data[0]

    def get_rear(self):
        if not self.is_empty():
            return self.data[len(self.data)-1]
```

---

<div style="page-break-after: always;"></div>

# 第6章 哈希表

## 6.1 哈希表

**哈希表（Hash Table）**

例如开发一个学生管理系统，需要有通过输入学号快速查出对应学生的姓名的功能。这里不必每次都去查询数据库，而可以在内存中建立一个缓存表，这样做可以提高查询效率。

再例如需要统计一本英文书里某些单词出现的频率，就需要遍历整本书的内容，把这些单词出现的次数记录在内存中。

<img src="./img/C6/6-1/1.png" style="zoom:67%;" />

<img src="./img/C6/6-1/2.png" style="zoom:67%;" />

因为这些需要，一个重要的数据结构诞生了，这个数据结构就是哈希表。哈希表也称散列表，哈希表提供了键（key）和值（value）的映射关系，只要给出一个`key`，就可以高效地查找到它所匹配的`value`，其时间复杂度接近于$ O(1) $。

<img src="./img/C6/6-1/3.png" style="zoom:67%;" />

哈希表的时间复杂度几乎是常量$ O(1) $，即查找时间与问题规模无关。

|                |    插入     |    删除     |                 查找                  |
| :------------: | :---------: | :---------: | :-----------------------------------: |
|    **数组**    |  $ O(n) $   |  $ O(n) $   | 顺序查找$ O(n) $；二分查找$ O(logn) $ |
|    **链表**    |  $ O(1) $   |  $ O(1) $   |               $ O(n) $                |
| **二叉搜索树** | $ O(logn) $ | $ O(logn) $ |              $ O(logn) $              |
| **平衡二叉树** | $ O(logn) $ | $ O(logn) $ |              $ O(logn) $              |

哈希表的两项基本工作：

1. 计算位置：构造哈希函数确定关键字的存储位置
2. 解决冲突：应用某种策略解决多个关键字位置相同的问题

<div style="page-break-after: always;"></div>

## 6.2 哈希函数

**哈希函数（Hash Function）**

哈希的基本思想是将键`key`通过一个确定的函数，计算出对应的函数值`value`作为数据对象的存储地址，这个函数就是哈希函数。

![](./img/C6/6-2/1.png)

哈希表本质上也是一个数组，可是数组只能根据下标来访问，而哈希表的`key`则是以字符串类型为主的。

在不同的语言中，哈希函数的实现方式是不一样的。假设需要存储整型变量，转化为数组的下标就不难实现了。最简单的转化方式就是按照数组长度进行取模运算。

一个好的哈希函数应该考虑两个因素：

1. 计算简单，以便提高转换速度。
2. 关键字对应的地址空间分布均匀，以尽量减少冲突



**数字关键字的哈希函数构造方法**

对于数字类型的关键字，哈希函数有以下几种常用的构造方法：

1. 直接定址法：取关键字的某个线性函数值为散列地址。

$$
h(key) = a * key + b\ (a,b\text{为常数})
$$

例如：根据出生年份计算人口数量$ h(key) = key - 1990 $：

|   地址    | 出生年份  |   人数    |
| :-------: | :-------: | :-------: |
|     0     |   1990    |  1285万   |
|     1     |   1991    |  1281万   |
|     2     |   1992    |  1280万   |
| $ \dots $ | $ \dots $ | $ \dots $ |
|    10     |   2000    |  1250万   |
| $ \dots $ | $ \dots $ | $ \dots $ |
|    21     |   2011    |  1180万   |

2. 除留余数法：哈希函数为$ h(key) = key\ mod\ p\ (p\text{一般取素数}) $。

例如$ h(key) = key\ \%\ 17 $：

|    地址    |  0   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |  9   |  10  |  11  |  12  |  13  |  14  |  15  |  16  |
| :--------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| **关键字** |  34  |  18  |  2   |  20  |      |      |  23  |  7   |  42  |      |  27  |  11  |      |  30  |      |  15  |      |

3. 数字分析法：分析数字关键字在各位上的变化情况，取比较随机的位作为散列地址。

例如取11位手机号码的后4位作为地址$ h(key) = Integer(key + 7) $。

再例如取18位身份证号码中变化较为随机的位数：

|  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |  9   |  10  |  11  |  12  |  13  |  14  |  15  |  16  |  17  |  18  |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  3   |  3   |  0   |  1   |  0   |  6   |  1   |  9   |  9   |  0   |  1   |  0   |  0   |  8   |  0   |  4   |  1   |  9   |
|  省  |  省  |  市  |  市  |  区  |  区  |  年  |  年  |  年  |  年  |  月  |  月  |  日  |  日  |  辖  |  辖  |  辖  | 校验 |

4. 折叠法：把关键字分割成位数相同的几个部分，然后叠加。

例如将整数$ 56793542 $每三位进行分割：
$$
\begin{array}{r}
542 \\
793 \\
+ 056 \\
\hline
1319 \\
\end{array}
$$

$$
h(56793542) = 319
$$

5. 平方取中法：计算关键字的平方，取中间几位。

例如整数$ 56793542 $：
$$
\begin{array}{r}
56793542 \\
\times 56793542 \\
\hline
3225506412905764 \\
\end{array}
$$

$$
h(56793542) = 641
$$



**字符串关键字的哈希函数构造方法**

对于字符串类型的关键字，哈希函数有以下几种常用的构造方法：

1. ASCII码加和法

$$
h(key) = \left( \sum key[i] \right)\ mod\ TableSize
$$

但是对于某些字符串会导致严重冲突，例如：`a3`、`b2`、`c1`或`eat`、`tea`等。

2. 移位法：取前3个字符移位，如：

$$
h(key) = \left( key[0] \times 27^2 + key[1] \times 27 | key[2] \right)\ mod\ TableSize
$$

对于一些字符串仍然会冲突，例如`string`、`strong`、`street`、`structure`等。

一个有效的改进是涉及关键字中所有$ n $个字符：
$$
h(key) = \left( \sum_{i=0}^{n-1} key[n-i-1] \times 32^i \right)\ mod\ TableSize
$$

---

【代码】快速计算$ h('abcde') = a * 32^4 + b * 32^3 + c * 32^2 + d * 32 + e $

```c
int hash(char *key, int tableSize) {
    int h = 0;          // hash value
    int i = 0;
    while(key[i] != '\0') {
        h = (h << 5) + key[i];
        i++;
    }
    return h % tableSize;
}
```

---

【代码】凯撒加密

```c
/**
 * @brief  凯撒加密
 * @note  加密算法：ciphertext[i] = (plaintext[i] + Key) % 128
 * @param  plaintext: 明文
 * @retval 密文
 */
char* encrypt(char *plaintext) {
    int n = strlen(plaintext);
    char *ciphertext = (char *)malloc((n + 1) * sizeof(char));
    for(int i = 0; i < n; i++) {
        ciphertext[i] = (plaintext[i] + KEY) % 128;
    }
    ciphertext[n] = '\0';
    return ciphertext;
}

/**
 * @brief  凯撒解密
 * @note   解密算法：plaintext[i] = (ciphertext[i] - key + 128) % 128
 * @param  ciphertext: 密文
 * @retval 明文
 */
char* decrypt(char *ciphertext) {
    int n = strlen(ciphertext);
    char *plaintext = (char *)malloc((n + 1) * sizeof(char));
    for(int i = 0; i < n; i++) {
        plaintext[i] = (ciphertext[i] - KEY + 128) % 128;
    }
    plaintext[n] = '\0';
    return plaintext;
}
```

---

<div style="page-break-after: always;"></div>

## 6.3 冲突处理

**装填因子（Load Factor）**

假设哈希表空间大小为$ m $，填入表中元素个数是$ n $，则称$ \alpha = n / m $为哈希表的装填因子。

当哈希表元素太多，即装填因子$ \alpha $太大时，查找效率会下降。实用最大装填因子一般取$ 0.5 \le \alpha \le 0.85 $。当装填因子过大时，解决的方法是加倍扩大哈希表，这个过程叫作再散列（rehashing）。

再散列的过程需要遍历原哈希表，把所有的关键字重新散列到新数组中。为什么需要重新散列呢？因为长度扩大以后，散列的规则也随之改变。经过扩容，原本拥挤的哈希表重新变得稀疏，原有的关键字也重新得到了尽可能均匀的分配。

装填因子也是影响产生哈希冲突的因素之一。当不同的关键字可能会映射到同一个散列地址上，就导致了哈希冲突（collision），即$ h(key_i) = h(key_j),\ key_i \ne key_j $，因此需要某种冲突解决策略。

例如有11个数据对象的集合$ {18, 23, 11, 20, 2, 7, 27, 30, 42, 15, 34, 35} $，哈希表的大小为$ 17 $，哈希函数选择$ h(key) = key\ mod\ size $。

|    地址    |  0   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |  9   |  10  |  11  |  12  |  13  |  14  |  15  |  16  |
| :--------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| **关键字** |  34  |  18  |  2   |  20  |      |      |  23  |  7   |  42  |      |  27  |  11  |      |  30  |      |  15  |      |

在插入最后一个关键字$ 35 $之前，都没有产生任何冲突。但是$ h(35) = 1 $，位置已有对象，就导致了冲突。



**冲突处理方法**

常用的处理冲突的思路有两种：

1. 开放地址法（open addressing）：一旦产生了冲突，就按某种规则去寻找另一空地址。开放地址法主要有线性探测法、平方探测法（二次探测法）和双散列法。
2. 分离链接法：将相应位置上有冲突的所有关键字存储在同一个单链表中。



**线性探测法（Linear Probing）**

当产生冲突时，以增量序列$ 1, 2, 3, ..., n-1 $循环试探下一个存储地址。

例如序列$ {47, 7, 29, 11, 9, 84, 54, 20, 30} $，哈希表表长为$ 13 $，哈希函数$ h(key) = key\ mod\ 11 $，用线性探测法处理冲突。

![](./img/C6/6-3/1.png)

线性探测法的缺陷在于容易出现聚集现象。



**平方探测法（Quadratic Probing）**

平方探测法也称为二次探测法，以增量序列$ 1^2, -1^2, 2^2, -2^2, \dots, q^2, -q^2 (q \le \lfloor size/2 \rfloor) $循环试探下一个存储地址。

例如序列$ {47, 7, 29, 11, 9, 84, 54, 20, 30} $，哈希表表长为$ 11 $，哈希函数$ h(key) = key\ mod\ 11 $，用平方探测法处理冲突。

![](./img/C6/6-3/2.png)

但是只要还有空间，平方探测法就一定能找到吗？

例如对于以下哈希表，插入关键字$ 11 $，哈希函数$ h(key) = key\ mod\ 5 $，用平方探测法处理冲突。

|    下标    |  0   |  1   |  2   |  3   |  4   |
| :--------: | :--: | :--: | :--: | :--: | :--: |
| **关键字** |  5   |  6   |  7   |      |      |

对关键字$ 11 $进行平方探测的结果一直在下标$ 0 $和$ 2 $之间波动，永远无法达到其它空的位置。

但是有定理证明，如果哈希表长度是某个$ 4k + 3\ (k \in Z^+)$形式的素数时，平方探测法就可以探查到整个哈希表空间。



**双散列探测法（Double Hashing）**

设定另一个哈希函数$ h_2(key) $，探测序列为$ h_2(key),\ 2h_2(key),\ 3h_2(key), \dots $

探测序列应该保证所有的散列存储单元都应该能够被探测到，选择以下形式有良好的效果：
$$
h_2(key) = p - (key\ mod\ p),\ p < TableSize,\ p,\ TableSize \in {素数}
$$


**分离链接法**

分离链接法也称拉链法、链地址法，将相应位置上有冲突的所有关键字存储在同一个单链表中。

例如关键字序列为$ {47, 7, 29, 11, 16, 92, 22, 8, 3, 50, 37, 89, 94, 21} $，哈希函数$ h(key) = key\ mod\ 11 $，用分离链接法处理冲突。

<img src="./img/C6/6-3/3.png" style="zoom: 60%;" />

<div style="page-break-after: always;"></div>

## 6.4 性能分析

**性能分析**

哈希表的平均查找长度（ASL, Average Search Length）用来度量哈希表查找效率。关键字的比较次数，取决于产生冲突的多少。影响产生冲突多少有三个因素：

1. 哈希函数是否均匀
2. 处理冲突的方法
3. 哈希表的装填因子$ \alpha $

合理的最大装填因子$ \alpha $应该不超过$ 0.85 $，选择合适的哈希函数可以使哈希表的查找效率期望是常数$ O(1) $，它几乎与关键字的空间大小$ n $无关。这是以较小的$ \alpha $为前提，因此哈希表是一个以空间换时间的结构。

哈希表的存储对关键字是随机的，因此哈希表不便于顺序查找、范围查找、最大值/最小值查找等操作。

<div style="page-break-after: always;"></div>

# 第7章 树

## 7.1 树

**树（Tree）**

<img src="./img/C7/7-1/1.png" style="zoom: 80%;" />

<img src="./img/C7/7-1/2.png" style="zoom: 80%;" />

<img src="./img/C7/7-1/3.png" style="zoom: 67%;" />

许多逻辑关系并不是简单的线性关系，在实际场景中，常常存在着一对多，甚至多对多的情况。树和图就是典型的非线性数据结构。

除了家谱是一个树，企业里的职级关系也是一个树：

<img src="./img/C7/7-1/4.png" style="zoom: 50%;" />

除了人与人之间的关系之外，许多抽象的东西也可以成为一个树，例如一本书的目录：

<img src="./img/C7/7-1/5.png" style="zoom: 50%;" />

这些结构都像自然界中的树一样，从同一个根衍生出许多枝干，再从每一个枝干衍生出许多更小的枝干，最后衍生出更多的叶子。

树是由$ n\ (n \ge 0) $个有限节点组成的一个具有层次关系的集合，当$ n = 0 $时称为空树。

在任意一个非空树中，有以下特点：

1. 有且有且仅有一个特定的结点称为根（root）。
2. 当$ n > 1 $时，其余结点可分为$ m\ (m > 0) $个互不相交的有限集$ T_1, T_2, \dots, T_m $，其中每一个集合本身又是一棵树，并且称为根的子树（subtree）。



**树的术语**

<img src="./img/C7/7-1/6.png" style="zoom:80%;" />

- 根：没有父结点（parent）的结点。
- 内部结点（internal node）：至少有一个子结点（child）的结点。
- 外部结点（external node） / 叶子结点（leaf node）：没有子结点的结点。
- 度（degree）：结点分支的个数。
- 路径（path）：从根结点到树中某结点经过的分支构成了路径。
- 祖先结点（ancestors）：包含父结点、父结点的父结点等。
- 子孙结点（descendants）：包含子结点、子结点的子结点等。
- 深度（depth） / 高度（height）：最大层级数。

<div style="page-break-after: always;"></div>

## 7.2 二叉树

**二叉树（Binary Tree）**

二叉树是树的一种特殊形式。二叉树的每个结点最多有两个孩子结点，即最多有`2`个，也可能只有`1`个，或者`没有`孩子结点。

二叉树结点的两个孩子结点，分别被称为`左孩子（left child）`和`右孩子（right child）`。这两个孩子结点的顺序是固定的，不能颠倒或混淆。

<img src="./img/C7/7-2/1.png" style="zoom:67%;" />

二叉树还有几种特殊的形式：

1. 左斜树（left skew tree） / 右斜树（right skew tree）：只有左子树或只有右子树的二叉树。

<img src="./img/C7/7-2/2.png" style="zoom: 67%;" />

2. 满二叉树（full binary tree）：所有非叶子结点都存在左右孩子，并且所有叶子结点都在同一层。

<img src="./img/C7/7-2/3.png" style="zoom:60%;" />

3. 完全二叉树：对于一个有$ n $个结点的二叉树，按层级顺序编号，则所有结点的编号从1到n，完全二叉树所有结点和同样深度的满二叉树的编号从$ 1 $到$ n $的结点位置相同。简单来说，就是除最后一层外，其它各层的结点数都达到最大，并且最后一层从右向左连续缺少若干个结点。

<img src="./img/C7/7-2/4.png" style="zoom:60%;" />



**二叉树的存储结构**

二叉树既可以通过链式存储，也可以使用数组存储：

1. 链式存储结构：一个结点最多可以指向左右两个孩子结点，所以二叉树的每一个结点包含三个部分：
    - 存储数据的数据域`data`
    - 指向左孩子的指针`left`
    - 指向右孩子的指针`right`

<img src="./img/C7/7-2/5.png" style="zoom: 67%;" />

2. 数组存储：按照层级顺序把二叉树的结点放到数组中对应的位置上。如果某一结点的左孩子或右孩子空缺，则数组的相应位置也空出来。

<img src="./img/C7/7-2/6.png" style="zoom:80%;" />

采用数组存储可以更方便地定位二叉树的孩子结点和父结点。假设一个父结点的下标是`parent`，那么它的左孩子结点的下标就是`2 * parent + 1`，右孩子结点的下标就是`2 * parent + 2`。反过来，假设一个左孩子结点的下标是`leftChild`，那么它的父结点的下标就是`(leftChild - 1) / 2`。

但是，对于一个稀疏的二叉树来说，用数组表示法是非常浪费空间的。对于一种特殊的完全二叉树——二叉堆而言，就是使用数组进行存储的。



**二叉树的应用**

二叉树包含许多特殊的形式，每一种形式都有自己的作用，但是其最主要的应用还在于进行查找操作和维持相对顺序这两个方面。

常用的二叉树包括：

1. 二叉搜索树（binary search tree）

<img src="./img/C7/7-2/7.png" style="zoom: 50%;" />

2. AVL树（AVL tree）

<img src="./img/C7/7-2/8.png" style="zoom:67%;" />

3. 红黑树（red black tree）

![](./img/C7/7-2/9.png)

4. 二叉堆（binary heap）

<img src="./img/C7/7-2/10.png" style="zoom: 50%;" />

5. 哈夫曼树（Huffman tree）

<img src="./img/C7/7-2/11.png" style="zoom: 50%;" />

二叉树还可以用在表达式求值中：

<img src="./img/C7/7-2/12.png" style="zoom: 67%;" />

<div style="page-break-after: always;"></div>

## 7.3 二叉树的遍历

**二叉树的遍历**

在计算机程序中，遍历（traversal）本身是一个线性操作，所以遍历同样具有线性结构的数组或链表是一件轻而易举的事情。

反观二叉树，是典型的非线性数据结构，遍历时需要把非线性关联的结点转化成一个线性的序列，以不同的方式来遍历，遍历出的序列顺序也不同。

二叉树的遍历方式分为`4`种：

1. 前序遍历（pre-order）：访问根结点，遍历左子树，遍历右子树。
2. 中序遍历（in-order）：遍历左子树，访问根结点，遍历右子树。
3. 后序遍历（post-order）：遍历左子树，遍历右子树，访问根结点。
4. 层次遍历（level-order）：按照从根结点到叶子结点的层次关系，一层一层横向遍历。



**前序遍历**

二叉树的前序遍历，首先访问根结点然后遍历左子树，最后遍历右子树。在遍历左、右子树时，仍然先访问根结点，然后遍历左子树，最后遍历右子树，如果结点为空则返回。

<img src="./img/C7/7-3/1.png" style="zoom: 67%;" />

---

【代码】前序遍历

```c
void preOrder(BST *root) {
    if(!root) {
        return;
    }
    printf("%d ", root->data);
    preOrder(root->left);
    preOrder(root->right);
}
```

---



**中序遍历**

二叉树的中序遍历，首先遍历左子树，然后访问根结点，最后遍历右子树，如果结点为空则返回。

<img src="./img/C7/7-3/2.png" style="zoom: 67%;" />

---

【代码】中序遍历

```c
void inOrder(BST *root) {
    if(!root) {
        return;
    }
    inOrder(root->left);
    printf("%d ", root->data);
    inOrder(root->right);
}
```

---



**后序遍历**

二叉树的后序遍历，首先遍历左子树，然后遍历右子树，最后访问根结点，如果结点为空则返回。

<img src="./img/C7/7-3/3.png" style="zoom: 67%;" />

---

【代码】后序遍历

```c
void postOrder(BST *root) {
    if(!root) {
        return;
    }
    postOrder(root->left);
    postOrder(root->right);
    printf("%d ", root->data);
}
```

---



**二叉树遍历非递归实现**

绝大多数可以用递归解决的问题，其实都可以用栈来解决，因为递归和栈都有回溯的特性。

以二叉树的中序遍历为例。当遇到一个结点时，就把它入栈，并去遍历它的左子树。当左子树遍历结束后，从栈顶弹出这个结点并访问它，然后按其右指针再去中序遍历该结点的右子树。

---

【代码】中序遍历（非递归）

```java
public void inOrderNonRecursive(BSTNode node) {
    Stack s = new Stack();
    while(node != null || !s.empty()) {
        // 一直向左并将沿途结点压入堆栈
        while(node != null) {
            s.push(node);
            node = node.left;
        }
        if(!s.empty()) {
            node = s.pop();					   //结点弹出堆栈
            System.out.println(node.data);		// 访问结点
            node = node.right;				   // 转向右子树
        }
    }
}
```

---



**层次遍历**

二叉树同一层次的结点之间是没有直接关联的，需要队列来辅助完成层序遍历。

层次遍历从根结点开始首先将根结点入队，然后开始循环执行以下操作直到队列为空：结点出队、访问该结点、其左右儿子入队。

---

【代码】层次遍历

```java
public void levelOrder(BSTNode node) {
    if(node == null) {
        return;
    }
    
    Queue q = new Queue();
    q.enqueue(node);
    while(!q.empty()) {
        node = q.dequeue();
        System.out.println(node.data);		// 访问结点
        if(node.left != null) {
            q.enqueue(node.left);
        }
        if(node.right != null) {
            q.enqueue(node.right);
        }
    }
}
```

---

<div style="page-break-after: always;"></div>

## 7.4 二叉搜索树

**二叉搜索树（Binary Search Tree）**

二叉搜索树，也称二叉查找树或二叉排序树，可以是一棵空树。

如果不为空树，那么二叉搜索树满足以下性质：

1. 非空左子树的所有结点的值小于其根结点的值。
2. 非空右子树的所有结点的值大于其根结点的值。
3. 左、右子树均是二叉搜索树

<img src="./img/C7/7-4/1.png" style="zoom: 67%;" />



**查找结点**

在二叉搜索树中查找一个元素从根结点开始，如果树为空，返回`NULL`。

如果树不为空，则将根结点的值和被查找的key值进行比较：

1. 如果key值小于根结点的值，只需在左子树中继续查找。
2. 如果key值大于根结点的值，只需在右子树中继续查找。
3. 如果key值与根结点的值相等，查找成功。

---

【代码】查找结点（递归）

```c
Node* search(Node *root, dataType val) {
    if(!root) {
        return NULL;
    }
    if(val == root->data) {
        return root;
    } else if(val < root->data) {
        return search(root->left, val);
    } else {
        return search(root->right, val);
    }
}
```

---

由于非递归函数的执行效率高，可将`尾递归`（在函数最后才使用递归返回）的函数改为迭代函数。

---

【代码】查找结点（迭代）

```c
Node* search(Node *root, dataType val) {
    if(!root) {
        return NULL;
    }  
    while(root) {
        if(root->data == val) {
            return root;
        } else if(val < root->data) {
            root = root->left;
        } else {
            root = root->right;
        }
    }
}
```

---



**查找最小值和最大值**

二叉搜索树中，最小值一定在树的最左分枝的叶子结点上，最大值一定在树的最右分枝的叶子结点上。

---

【代码】查找最小值（递归）

```c
Node* findMin(Node *root) {
	if(!root) {
        return NULL;
    } else if(!root->left) {
        return root;
    } else {
        return findMin(root->left);		//沿左分枝继续查找
    }
}
```

---

【代码】查找最大值（迭代）

```c
Node* findMax(Node *root) {
	if(!root) {
        return NULL;
    } 
    while(root->right) {
        root = root->right;
    }
    return root;
}
```

---



**插入结点**

在二叉搜索树中插入结点与查找的算法相似，需要找到插入的位置并将新结点插入。

---

【代码】插入结点

```c
BST* insert(BST *root, dataType val) {
    // 空树，插入结点设为树根
    if(!root) {
        return init(val);
    }
    if(val < root->data) {
        root->left = insert(root->left, val);
    } else {
        root->right = insert(root->right, val);
    }
    return root;
}
```

---

<div style="page-break-after: always;"></div>

## 7.5 堆排序

**堆（Heap）**

二叉堆本质上是一种完全二叉树，分为最大堆和最小堆两个类型。在最大堆中，任何一个父结点的值都大于等于它左右孩子结点的值。在最小堆中，任何一个父结点的值都小于等于它左右孩子结点的值。

<img src="./img/C7/7-5/1.png" style="zoom: 67%;" />

<img src="./img/C7/7-5/2.png" style="zoom: 67%;" />

二叉堆的根结点称为堆顶，在最大堆中堆顶是整个堆中的最大元素，在最小堆中堆顶是整个堆中的最小元素。

在二叉堆中插入结点、删除结点、构造二叉堆的操作都基于堆的自我调整。

二叉堆虽然是一棵完全二叉树，但它的存储方式并不是链式存储，而是顺序存储。数组中，通过下标可以定位到结点的左右孩子，假设父结点的下标是$ parent $，那么它的左孩子下标为$ 2 * parent + 1 $、右孩子下标为$ 2 * parent + 2 $。

<img src="./img/C7/7-5/3.png" style="zoom: 67%;" />



**插入/删除结点**

二叉堆的插入操作可以看成是结点上浮，当在堆中插入一个结点时，必须满足完全二叉树的标准，那么被插入结点的位置是完全二叉树的最后一个位置。在最大堆中，如果新结点的值大于它的父结点的值，则让新结点上浮，即和父结点交换位置。

堆的插入时间复杂度取决于树高为$ O(logn) $。

![](./img/C7/7-5/4.png)

二叉堆的删除操作总是从堆的根结点删除元素。根结点被删除之后为了能够保证该树还是一棵完全二叉树，需要将完全二叉树的最后一个结点补到根结点的位置，让其继续符合完全二叉树的定义。二叉堆的删除结点操作可以看作是结点下沉。在最大堆中，如果新堆顶元素小于它的左右孩子中较大的那个结点，则与它的较大的子结点交换位置。

堆的删除时间复杂度取决于树高为$ O(logn) $。

![](./img/C7/7-5/5.png)



**构建二叉堆**

构建二叉堆，就是把一个无序的完全二叉树调整为二叉堆，本质上就是让所有非叶子结点依次下沉。

<img src="./img/C7/7-5/6.png" style="zoom: 67%;" />

首先从最后一个非叶子结点开始，结点10下沉：

<img src="./img/C7/7-5/7.png" style="zoom: 67%;" />

结点3下沉：

<img src="./img/C7/7-5/8.png" style="zoom: 67%;" />

结点1不用改变。结点7下沉：

<img src="./img/C7/7-5/9.png" style="zoom: 67%;" />

最终一棵无序完全二叉树就调整成了一个最小堆。



**堆排序（Heap Sort）**

有了二叉堆的构建、删除和自我调节，实现堆排序就是水到聚成了。当删除一个最大堆的堆顶后（并不是完全删除，而是替换到堆的最后面），经过自我调节，第二大的元素就会被交换上来，成为最大堆的新堆顶。

![](./img/C7/7-5/10.png)

只要反复删除堆顶，反复调节二叉堆，所得到的的集合就成为了一个有序集合。

<img src="./img/C7/7-5/11.png" style="zoom: 50%;" />

---

【代码】堆排序

```java
public static void downAdjust(int[] arr, int parentIndex, int length) {
    // 保存父结点的值，用于最后的赋值
    int temp = arr[parentIndex];
    int childIndex = 2 * parentIndex + 1;

    while(childIndex < length) {
        // 如果有右孩子，且右孩子大于左孩子的值，则定位到右孩子
        if(childIndex + 1 < length 
           && arr[childIndex + 1] > arr[childIndex]) {
            childIndex++;
        }
        // 如果父结点小于任何一个孩子的值，直接跳出
        if(temp >= arr[childIndex]) {
            break;
        }
        // 无需真正交换，单向赋值即可
        arr[parentIndex] = arr[childIndex];
        parentIndex = childIndex;
        childIndex = 2 * childIndex + 1;
    }
    arr[parentIndex] = temp;
}

public static void heapSort(int[] arr) {
    // 把无序数组构建成二叉堆
    for(int i = (arr.length-2) / 2; i >= 0; i--) {
        downAdjust(arr, i, arr.length);
    }

    // 循环删除堆顶元素，移到数组尾部，调节堆产生新的堆顶
    for(int i = arr.length - 1; i > 0; i--) {
        // 最后一个元素和第一个元素交换
        int temp = arr[i];
        arr[i] = arr[0];
        arr[0] = temp;
        // 下沉调整最大堆
        downAdjust(arr, 0, i);
    }
}
```

---

堆排序的空间复杂度为$ O(1) $，因为算法并没有开辟额外的集合空间。

至于空间复杂度，假设二叉堆总共有$ n $个元素，那么下沉调整的最坏时间复杂度就等同于二叉堆的高度$ O(logn) $。

堆排序的算法步骤分为两部分：

1. 把无序数组构建成二叉堆：进行$ n / 2 $次循环，每次循环进行一次下沉调节，因为此步骤的计算规模为$ n/2 * logn $，时间复杂度为$ O(nlogn) $。
2. 循环删除堆顶元素，移到数组尾部，调节堆产生新堆顶：进行$ n - 1 $次循环，每次循环进行一次下沉调节，因此次步骤的计算规模为$ (n-1) * logn $，时间复杂度为$ O(nlogn) $。

综合堆排序的两个步骤，整体时间复杂度为$ O(nlogn) $。

<div style="page-break-after: always;"></div>

## 7.6 哈夫曼树

**哈夫曼树（Huffman Tree）**

树的每一个结点都可以拥有自己的权值（weight），假设二叉树有$ n $个叶子结点，每个叶子结点都带有权值$ w_k $，从根结点到每个叶子结点的长度为$ l_k $，则树的带权路径长度（WPL, Weighted Path Length）为：
$$
WPL = \sum_{k=1}^n w_k l_k
$$
哈夫曼树是由麻省理工学院的哈夫曼博士于1952年发明的，哈夫曼树是在叶子结点和权重确定的情况下，带权路径长度最小的二叉树，也被称为最优二叉树。

例如，有五个叶子结点，它们的权值为$ \{1, 2, 3, 4, 5\} $，用此权值序列可以构造出形状不同的多个二叉树。

![](./img/C7/7-6/1.png)
$$
\begin{aligned}
WPL_1 &= 5 * 1 + 4 * 2 + 3 * 3 + 2 * 4 + 1 * 4 = 34 \\
WPL_2 &= 1 * 1 + 2 * 2 + 3 * 3 + 4 * 4 + 5 * 4 = 50 \\
WPL_3 &= 3 * 2 + 4 * 2 + 5 * 2 + 1 * 3 + 2 * 3 = 33
\end{aligned}
$$
​	怎样才能保证构建出的二叉树带权路径长度最小呢？原则上，应该让权重小的叶子结点远离树根，权重大的叶子结点靠近树根。需要注意的是，同样叶子结点所构成的哈夫曼树可能不止一棵。



**哈夫曼树的构造**

哈夫曼树的构造方法就是每次把权值最小的两棵二叉树合并。

例如有$ 6 $个叶子结点，权重依次是$ 2, 3, 7, 9, 18, 25 $。

第一步：把每一个叶子结点都当成一棵独立的树（只有根结点的树），这样就形成了一个森林。

<img src="./img/C7/7-6/2.png" style="zoom:67%;" />

第二步：从森林中移除权值最小的两个结点，生成父结点，父结点的权值是这两个结点权值之和，把父结点加入森林。重复该步骤，直到森林中只有一棵树为止。

<img src="./img/C7/7-6/3.png" style="zoom:67%;" />

<img src="./img/C7/7-6/4.png" style="zoom:67%;" />

<img src="./img/C7/7-6/5.png" style="zoom:67%;" />

<img src="./img/C7/7-6/6.png" style="zoom:67%;" />

<img src="./img/C7/7-6/7.png" style="zoom:67%;" />

哈夫曼树有以下几个特点：

1. 没有度为$ 1 $的结点。
2. 哈夫曼树的任意非叶结点的左右子树交换后仍是哈夫曼树。
3. 对同一组权值，可能存在不同构的两棵哈夫曼树

![](./img/C7/7-6/8.png)

<div style="page-break-after: always;"></div>

## 7.7 哈夫曼编码

**哈夫曼编码（Huffman Code）**

哈夫曼编码是一种高效的编码方式，在信息存储和传输过程中用于对信息进行压缩。要理解哈夫曼编码，需要从信息存储的底层逻辑讲起。

计算机不是人，它不认识中文和英文，更不认识图片和视频，它唯一认识的就是`0（低电平）`和`1（高电平）`。因此，计算机上一切文字、图象、音频、视频，底层都是用二进制来存储和传输的。

将信息转换成计算机能够识别的二进制形式的过程被称为编码。在ASCII码中，每一个字符表示成特定的`8`位二进制数。例如：

![](./img/C7/7-7/1.png)

显然，ASCII码是一种等长编码，也就是任何字符的编码长度都相等。等长编码的有点明显，因为每个字符对应的二进制编码长度相等，所以很容易设计，也很方便读写。但是计算机的存储空间以及网络传输的带宽是有限的，等长编码最大的缺点就是编码结果太长，会占用过多资源。

使用不等长编码，让出现频率高的字符用的编码短一些，出现频率低的字符编码长一些，可以使编码的总长度减小。但是不等长编码是不能随意设计的，如果一个字符的编码恰好是另一个字符编码的前缀，就会产生歧义的问题。

哈夫曼编码就是一种不等长的编码，并且任何一个字符的编码都不是另一个字符编码的前缀，因此可以无二义地进行解码，并且信息编码的总长度最小。

哈夫曼编码并非一套固定的编码，而是根据给定信息中各个字符出现的频次，动态生成最优的编码。哈夫曼编码的生成过程就用到了哈夫曼树。

例如一段信息里只有A、B、C、D、E、F这6个字符，出现的次数分别是2次、3次、7次、9次、18次、25次。通过把这6个字符当成6个叶子结点，将出现次数作为结点的权重，生成一颗哈夫曼树。将哈夫曼树中结点的左分支当做0、结点的右分支当做1，从哈夫曼树的根结点到每一个叶子结点的路径，都可以等价为一段二进制编码。

![](./img/C7/7-7/2.png)

因为每一个字符对应的都是哈夫曼树的叶子结点，从根结点到这些叶子结点的路径并没有包含关系，最终得到的二进制编码自然也不会是彼此的前缀。

<div style="page-break-after: always;"></div>

# 第8章 图

## 8.1 图

**图（Graph）**

例如，你的微信中有若干好友，而你的好友又有若干好友。

<img src="./img/C8/8-1/1.png" style="zoom: 50%;" />

许许多多的用户组成了一个多对多的关系网，这个关系网就是数据结构中的图。

再例如使用地图导航功能时，导航会根据你的出发地和目的地规划最佳的地铁换乘路线。许许多多的地铁站组成的交通网络也可以认为是图。

<img src="./img/C8/8-1/2.png" style="zoom: 50%;" />

图是一种比树更为复杂的数据结构。树的结点之间是一对多的关系，并且存在父与子的层级划分。而图的顶点之间是多对多关系，并且所有顶点都是平等的，无所谓谁是父子。

在图中，最基本的单元是顶点（vertex），相当于树中的结点。顶点之间的关联关系被称为边（edge）。图中包含一组顶点和一组边，通常用$ V $表示顶点集合，用$ E $表示边集合。边可以看作是顶点对，即$ (v, w) \in E,\ v, w \in V $。

在有些图中，每一条边并不是完全等同的。例如地铁线路，站与站之间的距离都有可能不同。因此图中会涉及边的权重（weight），涉及到权重的图被称为带权图（weighted graph），也称为网络。

<img src="./img/C8/8-1/3.png" style="zoom:67%;" />

还有一种图，顶点之间的关联并不是完全对称的。拿微信举例，你的好友列表里有我，但我的好友列表里未必有你。

<img src="./img/C8/8-1/4.png" style="zoom: 67%;" />

<img src="./img/C8/8-1/5.png" style="zoom:67%;" />

<img src="./img/C8/8-1/6.png"  />

<img src="./img/C8/8-1/7.png" style="zoom:67%;" />

这样一来，顶点之间的边就有了方向的区分，这种带有方向的图被称为有向图（directed graph）。有向边可以使用$ <v, w> $表示从$ v $指向$ w $的边。

<img src="./img/C8/8-1/8.png" style="zoom: 50%;" />

相应地，在QQ中，只要我把你从好友里删除，你在自己的好友列表里就看不到我了。因此QQ的好友关系可以认为是一个没有方向区分的图，这种图被称为无向图（undirected graph）。

<div style="page-break-after: always;"></div>

## 8.2 图的表示

**邻接矩阵（Adjacency Matrix）**

拥有$ n $个顶点的图，它所包含的边的数量最多是$ n(n-1) $条，因此，要表达各个顶点之间的关联关系，最清晰易懂的方式是使用邻接矩阵$ G[N][N] $。

对于无向图来说，如果顶点之间有关联，那么邻接矩阵中对应的值为`1`；如果顶点之间没有关联，那么邻接矩阵中对应的值为`0`。
$$
G[i][j] = \left\{
\begin{aligned}
& 1 & <v_i, v_j>\text{是}G\text{中的边} \\
& 0 & <v_i, v_j>\text{不是}G\text{中的边} \\
\end{aligned}
\right.
$$

```mermaid
graph LR
	V0((V0))
	V1((V1))
	V2((V2))
	V3((V3))
	V4((V4))
	
	V0 --- V1
	V0 --- V3
	V1 --- V2
	V2 --- V3
	V2 --- V4
```

|   G    |  V0  |  V1  |  V2  |  V3  |  V4  |
| :----: | :--: | :--: | :--: | :--: | :--: |
| **V0** |  0   |  1   |  0   |  1   |  0   |
| **V1** |  1   |  0   |  1   |  0   |  0   |
| **V2** |  0   |  1   |  0   |  1   |  1   |
| **V3** |  1   |  0   |  1   |  0   |  0   |
| **V4** |  0   |  0   |  1   |  0   |  0   |

需要注意的是，邻接矩阵从左上到右下的一条对角线上的元素值必然是0，因为任何一个顶点与它自身是没有连接的。同时，无向图对应的邻接矩阵是一个对称矩阵，假如V1和V2有关联，那么V2和V1也必定有关联。

但是对于有向图的邻接矩阵，不一定是一个对称矩阵，假如V1可以达到V2，从V2未必能达到V1。

```mermaid
graph LR
	V0((V0))
	V1((V1))
	V2((V2))
	V3((V3))
	
	V0 --> V1
	V0 --> V2
	V2 --> V3
	V3 --> V1
	V3 --> V2
```

|   G    |  V0  |  V1  |  V2  |  V3  |
| :----: | :--: | :--: | :--: | :--: |
| **V0** |  0   |  1   |  1   |  0   |
| **V1** |  0   |  0   |  0   |  0   |
| **V2** |  0   |  0   |  0   |  1   |
| **V3** |  0   |  1   |  1   |  0   |

对于网络，只要把邻接矩阵对应位置的值定义为边$ <v_i, v_j> $的权重即可。

<img src="./img/C8/8-2/1.png" style="zoom:80%;" />

|   G    |  V0  |  V1  |  V2  |  V3  |  V4  | V5 |
| :----: | :--: | :--: | :--: | :--: | :--: | :--: |
| **V0** |     |  5  |     |     |     |  2  |
| **V1** |     |     |  4  |     |     |     |
| **V2** |     |     |     |  9  |     |     |
| **V3** |     |     |     |     |  7  |  3  |
| **V4** |  1  |     |     |     |     |     |
| **V5** |     |     |  1  |     |  8  |     |

但如果$ v_i $和$ v_j $之前没有边该怎么表示？还是设为0吗？

<img src="./img/C8/8-2/2.png" style="zoom:50%;" />

邻接矩阵的优点：

1. 简单、直观。
2. 可以快速查到一个顶点和另一顶点之间的关联关系。
3. 方便计算任一顶点的度，对于有向图，从顶点发出的边数为`出度`，指向顶点的边数为`入度`。

邻接矩阵的缺点：

1. 浪费空间，对于稀疏图（点很多而边很少）有大量无效元素。但对于稠密图（特别是完全图）还是很合算的。
2. 浪费时间，统计稀疏图中边的个数，也就是计算邻接矩阵中元素`1`的个数。

<img src="./img/C8/8-2/3.png" style="zoom:50%;" />



**邻接表（Adjacency List）**

为了解决邻接矩阵占用空间的问题，人们想到了另一种图的表示方法——邻接表。在邻接表中，图的每一个顶点都是一个链表的头结点，其后连接着该顶点能够直接到达的相邻顶点。对于稀疏图而言，邻接表存储方式占用的空间比邻接矩阵要小得多。

<img src="./img/C8/8-2/4.png" style="zoom:80%;" />

通过遍历邻接表可以查找到所有能够到达的相邻顶点，但是对于逆向查找，即哪些顶点可以达到一个顶点就会很麻烦。

通过逆邻接表可以解决逆向查找的麻烦。逆邻接表和邻接表是正好相反的，逆邻接表每一个顶点作为链表的头结点，后继结点所存储的是能够直接到达该顶点的相邻顶点。

<img src="./img/C8/8-2/5.png" style="zoom:80%;" />

<img src="./img/C8/8-2/6.png" style="zoom:67%;" />

<img src="./img/C8/8-2/7.png" style="zoom:67%;" />

<img src="./img/C8/8-2/8.png" style="zoom:80%;" />

<div style="page-break-after: always;"></div>

## 8.3 图的遍历

**深度优先搜索（DFS, Depth First Search）**

深度优先搜索是一种一头扎到底的遍历方法，选择一条支路，尽可能不断地深入，如果遇到死路就回退，回退过程中如果遇到没探索的支路，就进入该支路继续深入。

例如有一个小镇，你知道小镇的每个地方与每条路。小镇的每个地方都藏有可以实现愿望的光玉，现在你要出发去收集小镇上所有的光玉。你的出生点在0号位置，你需要一个地点都不遗漏地走完整个小镇，才能收集完所有光玉。

<img src="./img/C8/8-3/1.png" style="zoom: 67%;" />

二叉树的先序遍历本质上也可以认为是图的深度优先遍历。要想实现回溯，可以利用栈的先进后出的特性，也可以采用递归的方式，因为递归本身就是基于方法调用栈来实现的。

---

【代码】深度优先搜索

```
dfs(Vertex V):
    isVisited[V] = true
    for(v in V)
        if(!isVisited[v])
            dfs(v)
```

---



**广度优先搜索（BFS, Breath First Search）**

除了深度优先搜索一头扎到底的方法以外，还有一种方法就是首先把从源点相邻的顶点遍历，然后再遍历稍微远一点的顶点，再去遍历更远一点的顶点。

二叉树的层次遍历本质上也可以认为是图的广度优先遍历，需要借助队列来实现重放。

<img src="./img/C8/8-3/2.png" style="zoom:80%;" />

---

【代码】广度优先搜索

```
bfs(Vertex V):
    isVisited[V] = true
    enqueue(Q, V)
    while(!isEmpty(Q))
        V = dequeue(Q)
        for(v in V)
            if(!isVisited[v])
                isVisited[v = true
                enqueue(Q, v)
```

---

<div style="page-break-after: always;"></div>

## 8.4 连通图

**连通图**

图还有一些有关路径的术语：

- 连通：如果从顶点$ V $到$ W $存在一条路径，则称$ V $和$ W $是连通的。
- 路径：顶点$ V $到$ W $的路径是一系列顶点$ \{V, v_1, v_2, \dots, v_n, W\} $的集合，其中任意一对相邻的顶点间都有图中的边。
- 路径长度：路径中边的个数，如果是带权图（网络），则是所有边的权重和。
- 简单路径：顶点$ V $到$ W $之间的路径中所有顶点都不同。
- 回路：起点等于终点的路径。

如果图中任意两顶点均连通，那么称这个图是一个连通图。

一个图的连通分量指的是图的极大连通子图，极大连通子图需要满足两点要求：

1. 顶点数到达极大，即再加一个顶点就不连通了。
2. 边数达到极大，即包含子图中所有顶点相连的所有边。

<img src="./img/C8/8-4/1.png" style="zoom:90%;" />

对于有向图而言，如果有向图中任意一对顶点$ V $和$ W $之间存在双向路径，既可以从$ V $走到$ W $，也可以从$ W $走到$ V $，但这两条路径不一定是同一条，则称该图为强连通图。

如果有向图不是强连通图，但将所有的有向边替换为无向边之后可以变为连通图，则称该图为弱连通图。

有向图的极大强连通子图称为强连通分量。

<img src="./img/C8/8-4/2.png" style="zoom:90%;" />



**非连通图的遍历**

如果一个图不是连通图，那么无论使用深度优先遍历还是广度优先遍历，都会有顶点无法被访问到。解决这个问题的方式是每调用一次`dfs(V)`或`bfs(V)`，就把顶点$ V $所在的连通分量遍历一遍。

---

【代码】非连通图的深度优先遍历

```
dfs(Vertex V):
    isVisited[V] = true
    for(v in V)
        if(!isVisited[v])
            dfs(v)

listComponents(Graph G):
    for(V in G)
        if(!isVisited[V])
            dfs(V)
```

---

<div style="page-break-after: always;"></div>

## 8.5 最短路径

**最短路径（Shortest Path）**

在现实中很多需要都运用到了最短路径的算法，例如从一个地铁站到另一个地铁站的最快换乘路线等。地铁线路图中，地铁站可以看作是图的顶点，站与站之间的线路可以看作是边，权重可以是距离、时间、费用等。

<img src="./img/C8/8-5/1.png" style="zoom: 33%;" />

在网络中，求两个不同顶点之间的所有路径中，边的权值之和最小的那一条路径，这条路径就是两点之间的最短路径。其中最短路径的第一个顶点称为源点（source），最后一个顶点为终点（destination）。

图的最短路径问题分为2种类型：

1. 单源最短路径：从某固定源点出发，求到所有其它顶点的最短路径。
2. 多源最短路径：求任意两顶点间的最短路径。



**无权图的单源最短路径算法（SSSP, Single-Source Shortest Path）**

无权图的单源最短路径算法可以按照递增（非递减）的顺序找出到各个顶点的最短路，算法类似广度优先遍历。

<img src="./img/C8/8-5/2.png" style="zoom:90%;" />

---

【代码】无权图的单源最短路径

```
unweightedSSSP(Vertex S):
    enqueue(Q, S)
    while(!isEmpty(Q))
        V = dequeue(Q)
        for(v in V)
            if(dist[v] == -1)
                dist[v] = dist[V] + 1
                path[v] = V
                enqueue(Q, v)
```

---

无权图的单元最短路径算法中，`dist[v]`存储从源点$ S $到$ v $的最短路径，初始化源点`dist[S]`的距离为$ 0 $，`path[v]`表示达到顶点路径$ v $上一个经过的顶点。

|   顶点   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |
| :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| **dist** |  1   |  2   |  0   |  2   |  3   |  1   |  3   |
| **path** |  3   |  1   |  -1  |  1   |  2   |  3   |  4   |



**有权图的单源最短路径算法**

有权图的最短路径不一定是经过顶点树最少的路。如果图中存在负值圈（negative-cost cycle）的话会导致算法失效，因为沿着回路走无穷多次，花销是负无穷。

<img src="./img/C8/8-5/3.png" style="zoom:90%;" />

<img src="./img/C8/8-5/4.png" style="zoom:90%;" />

<img src="./img/C8/8-5/5.png" style="zoom: 60%;" />

<img src="./img/C8/8-5/6.png" style="zoom: 60%;" />

<img src="./img/C8/8-5/7.png" style="zoom: 60%;" />

<img src="./img/C8/8-5/8.png" style="zoom: 60%;" />

迪杰斯特拉（Dijkstra）算法的本质是不断刷新起点与其他各个顶点之间的距离表。`Dijkstra`算法采用了贪心的思想，每次都未收录的顶点中选取`dist`值最小的收录。每当收录一个顶点时，可能会影响另外一个顶点的`dist`值。
$$
dist[w] = min\{dist[w], dist[v] + weight_{<v, w>}\}
$$
例如计算从源点$ A $到其它各顶点的最短路径。

第1步：创建距离表。其中表中`key`是顶点名称，`value`是源点$ A $到对应顶点的已知最短距离。一开始并不知道最短路径是多少，因此`value`都为无穷大。

<img src="./img/C8/8-5/9.png" style="zoom: 67%;" />

第2步：找到源点$ A $的邻接点$ B $和$ C $，从$ A $到$ B $的距离是`5`，从$ A $到$ C $的距离是`2`。更新距离表。

<img src="./img/C8/8-5/10.png" style="zoom: 67%;" />

第3步：从距离表中找到从$ A $出发距离最短的顶点，也就是顶点$ C $。找到顶点$ C $的邻接点$ D $和$ F $（$ A $已经遍历过不需要考虑）。从$ C $到$ D $的距离是`6`，所以从$ A $到$ D $的距离是`2 + 6 = 8`；从$ C $到$ F $的距离是`8`，所以从$ A $到$ F $的距离是`2 + 8 = 10`。更新距离表。

<img src="./img/C8/8-5/11.png" style="zoom: 67%;" />

第4步：从距离表中找到从$ A $出发距离最短的顶点（$ C $已经遍历过不需要考虑），也就是顶点$ B $。找到顶点$ B $的邻接点$ D $和$ E $（$ A $已经遍历过不需要考虑）。从$ B $到$ D $的距离是`1`，所以从$A $到$ D $的距离是`5 + 1 = 6`，小于距离表中的`8`；从$ B $到$ E $的距离是`6`，所以从$ A $到$ E $的距离是`5 + 6 = 11`。更新距离表。

<img src="./img/C8/8-5/12.png" style="zoom: 67%;" />

第5步：从距离表中找到从$ A $出发距离最短的顶点（$ B $和$ C $不用考虑），也就是顶点$ D $。找到顶点$ D $的邻接点$ E $和$ F $。从$ D $到$ E $的距离是`1`，所以从$ A $到$ E $的距离是`6 + 1 = 7`，小于距离表中的`11`；从$ D $到$ F $的距离是`2`，所以从$ A $到$ F $的距离是`6 + 2 = 8`，小于距离表中的`10`。更新距离表。

<img src="./img/C8/8-5/13.png" style="zoom: 67%;" />

第6步：从距离表中找到从$ A $出发距离最短的顶点，也就是顶点$ E $。找到顶点$ E $的邻接点$ G $。从$ E $到$ G $的距离是`7`，所以从$ A $到$ G $的距离是`7 + 7 = 14`。更新距离表。

<img src="./img/C8/8-5/14.png" style="zoom: 67%;" />

第7步：从距离表中找到从$ A $出发距离最短的顶点，也就是顶点$ F $。找到顶点$ F $的邻接点$ G $。从$ F $到$ G $的距离是`3`，所以从$ A $到$ G $的距离是`8 + 3 = 11`，小于距离表中的`14`。更新距离表。

<img src="./img/C8/8-5/15.png" style="zoom: 67%;" />

最终，距离表中存储的是从源点$ A $到所有顶点的最短距离。



**多源最短路径算法**

<img src="./img/C8/8-5/16.png" style="zoom: 67%;" />

<img src="./img/C8/8-5/17.png" style="zoom: 67%;" />

<img src="./img/C8/8-5/18.png" style="zoom: 67%;" />

弗洛伊德（Floyd-Warshall）算法是专门用于寻找带权图中多源点之间的最短路径算法。`Floyd`算法的思想是，若想缩短两点间的距离，仅有一种方式，那就是通过第三顶点绕行。

假设$ D^k[i][j]$为路径$ \{i \rarr \{l \le k\} \rarr j\} $的最小长度。当$ D^{k-1} $已经完成，递推到$ D^k $时：

1. 如果$ k \notin \text{最短路径}\{i \rarr \{l \le k\} \rarr j\} $，则$ D^k = D^{k-1} $。
2. 如果$ k \in \text{最短路径}\{i \rarr \{l \le k\} \rarr j\} $，该路径必定由两段最短路径组成，则$ D^k[i][j] = D^{k-1}[i][k] + D^{k-1}[k][j] $。

例如，小哼准备去一些城市旅游，有些城市之间有公路，有些城市之间则没有。为了节省经费以及方便计划旅程，小哼希望在出发之前直到任意两个城市之间的最短路程。

<img src="./img/C8/8-5/19.png" style="zoom: 67%;" />

如果要让任意两点之间的路程变短，只能引入第三个点，并通过这个顶点中转才有可能缩短原来的路程。这个中转的顶点甚至有时候不只通过一个顶点，而是经过两个或更多点中转会更短。

当任意两点之间不允许经过第三个点中转时，这些城市之间的最短路径就是邻接矩阵的初始路径。

<img src="./img/C8/8-5/20.png"  />

在只允许经过$ 1 $号顶点中转的情况下，任意两点之间的最短路程更新为：

![](./img/C8/8-5/21.png)

在只允许经过$ 1 $号和$ 2 $号顶点中转的情况下，任意两点之间的最短路程更新为：

![](./img/C8/8-5/22.png)

在只允许经过$ 1 $号、$ 2 $号和$ 3 $号顶点中转的情况下，任意两点之间的最短路程更新为：

![](./img/C8/8-5/23.png)

最后允许通过所有顶点作为中转，任意两点之间的最短路程更新为：

![](./img/C8/8-5/24.png)

---

【代码】Floyd最短路径

```c
void floyd(Graph *g, int dist[MAX][MAX]) {
    // 最短路径矩阵初始化为图的邻接矩阵
    for(int i = 0; i < g->vertexNum; i++) {
        for(int j = 0; j < g->vertexNum; j++) {
            dist[i][j] = g->weight[i][j];
        }
    }

    // Floyd算法
    for(int k = 0; k < g->vertexNum; k++) {
        for(int i = 0; i < g->vertexNum; i++) {
            for(int j = 0; j < g->vertexNum; j++) {
                if(dist[i][k] + dist[k][j] < dist[i][j]) {
                    dist[i][j] = dist[i][k] + dist[k][j];
                }
            }
        }
    }
}
```

---

<div style="page-break-after: always;"></div>

## 8.6 最小生成树

**最小生成树（MST, Mininum Spanning Tree）**

所谓最小生成树，就是一个图的极小连通子图，它包含原图的所有顶点，并且所有边的权值之和尽可能小。

最小生成树需要满足3个条件：

1. 是一棵树：树不能有回路，并且$ |V| $个顶点一定有$ |V| - 1 $条边。
2. 是生成树：包含原图的全部顶点，树的$ |V| - 1 $条边都必须在图里，并且如果向生成树中任意加一条边都一定构成回路。
3. 边的权重和最小。

如果最小生成树存在，那么图一定连通，反之亦然。

例如一个带权图，绿色边可以把所有顶点连接起来，又保证边的权值和最小。

<img src="./img/C8/8-6/1.png" style="zoom: 50%;" />

<img src="./img/C8/8-6/2.png" style="zoom: 50%;" />

图的最小生成树不是唯一的，同一个图有可能对应多个最小生成树。

最小生成树在现实中很很多用处。假如要在若干个城市之间铺设铁路，而预算又是有限的，那么就需要寻找成本最低的铺设方式。城市之间的交通网就像一个连通图，其实并不需要在每两个城市之间都直接进行连接，只需要一个最小生成树，保证所有的城市都有铁路可以达到即可。

获得最小生成树的常用算法有2个：

- `Prim`
- `Kruskal`



**Prim**

`Prim`算法是以图的顶点为基础，从一个初始顶点开始，寻找达到其它顶点权值最小的边，并把该顶点加入到已触达顶点的集合中。当全部顶点都加入到集合时，算法的工作就完成了。`Prim`算法的本质是基于贪心算法（greedy algorithm）。

`Prim`算法可以理解为让一棵小树长大，每次找能够向外生长的最小边。

例如使用`Prim`算法获得一个带权图的最小生成树：

![](./img/C8/8-6/3.png)



**Kruskal**

与`Prim`算法不同，`Prim`算法是以顶点为关键来获得最小生成树的，而`Kruskal`算法是以边为关键获得最小生成树的。

`Kruskal`算法可以理解为将森林合并成树，每次在图中找权值最小的边收录。

例如使用`Kruskal`算法获得一个带权图的最小生成树：

![](./img/C8/8-6/4.png)

<div style="page-break-after: always;"></div>

## 8.7 拓扑排序

**拓扑排序（Topological Sort）**

一项大的工程常被分为多个小的子工程，子工程之间可能存在一定的先后顺序，即某些子工程必须在其它的一些子工程完成后才能开始。在现代化管理中，有向图可以用来描述和分析一项工程的计划和实施过程，其中图的顶点表示活动，有向边表示活动之间的先后关系，这样的图称为`AOV（Activity on Vertex）`网。

```mermaid
graph LR
	A --> B
	B --> C
	B --> D
	B --> E
	C --> E
	D --> E
	E --> F
```

如果图中从顶点$ V $到$ W $有一条有向路径，则$ V $一定排在$ W $之前，满足此条件的顶点序列称为一个拓扑序。`AOV`网如果有合理的拓扑序，则必定是有向无环图（DAG, Directed Acyclic Graph）。

<img src="./img/C8/8-7/1.png" style="zoom:67%;" />

可以使用卡恩`Kahn`算法完成拓扑排序。假设列表$ L $用于存放拓扑排序的结果，把所有入度为`0`的顶点放入$ L $中，然后把这些顶点从图中去掉。重复该操作，直到找不到入度为`0`的顶点。如果此时$ L $中的元素个数和图的顶点总数相同，说明拓扑排序完成；如果此时$ L $中的元素个数少于图的顶点总数，说明原图中存在环，无法进行拓扑排序。

例如对计算机专业课安排学习顺序：

| 课程代码 |       课程名称       | 预修课程 |
| :------: | :------------------: | :------: |
|    C1    |     程序设计基础     |    无    |
|    C2    |       离散数学       |    无    |
|    C3    |       数据结构       |  C1、C2  |
|    C4    |     微积分（一）     |    无    |
|    C5    |     微积分（二）     |    C4    |
|    C6    |       线性代数       |    C5    |
|    C7    |    算法分析与设计    |    C3    |
|    C8    | 逻辑与计算机设计基础 |    无    |
|    C9    |      计算机组成      |    C8    |
|   C10    |       操作系统       |  C7、C9  |
|   C11    |       编译原理       |  C7、C9  |
|   C12    |        数据库        |    C7    |
|   C13    |       计算理论       |    C2    |
|   C14    |      计算机网络      |   C10    |
|   C15    |       数值分析       |    C6    |

```mermaid
graph LR
	C1 --> C3
	C2 --> C3
	C2 --> C13
	C3 --> C7
	C4 --> C5
	C5 --> C6
	C6 --> C15
	C7 --> C10
	C7 --> C11
	C7 --> C12
	C8 --> C9
	C9 --> C10
	C9 --> C11
	C10 --> C14
```

```mermaid
graph LR
	C3 --> C7
	C5 --> C6
	C6 --> C15
	C7 --> C10
	C7 --> C11
	C7 --> C12
	C9 --> C10
	C9 --> C11
	C10 --> C14
	C13

	subgraph SEMASTERS
		subgraph semaster 1
			C1/C2/C4/C8
		end
	end
```

```mermaid
graph LR
	C6 --> C15
	C7 --> C10
	C7 --> C11
	C7 --> C12
	C10 --> C14

	subgraph SEMASTERS
		subgraph semaster 1
			C1/C2/C4/C8
		end
		
		subgraph semaster 2
			C3/C5/C9/C13
		end
	end
```

```mermaid
graph LR
	C10 --> C14
	C11
	C12
	C15

	subgraph SEMASTERS
		subgraph semaster 1
			C1/C2/C4/C8
		end
		
		subgraph semaster 2
			C3/C5/C9/C13
		end
		
		subgraph semaster 3
			C6/C7
		end
	end
```

```mermaid
graph LR
	C14

	subgraph SEMASTERS
		subgraph semaster 1
			C1/C2/C4/C8
		end
		
		subgraph semaster 2
			C3/C5/C9/C13
		end
		
		subgraph semaster 3
			C6/C7
		end
		
		subgraph semaster 4
			C10/C11/C12/C15
		end
	end
```

```mermaid
graph LR
	subgraph SEMASTERS
		subgraph semaster 1
			C1/C2/C4/C8
		end
		
		subgraph semaster 2
			C3/C5/C9/C13
		end
		
		subgraph semaster 3
			C6/C7
		end
		
		subgraph semaster 4
			C10/C11/C12/C15
		end
		
		subgraph semaster 5
			C14
		end
	end
```

